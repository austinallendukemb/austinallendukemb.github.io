[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Austin’s MB Projects",
    "section": "",
    "text": "Introduction to Statistical Theory and Methods I (BIOSTAT 701)\nApplied Biostatistical Methods I (BIOSTAT 702)\nIntroduction to the Practice of Biostatistics I (BIOSTAT 703)\nBiostatistics Career Preparation and Development I (BIOSTAT 801)\nProgramming, Data Structures, and Algorithms in C++ (ECE 551D)\n\n(Note: This website was created after this semester was completed, so projects may not have been uploaded yet)\n\n\n\n\nIntroduction to Statistical Theory and Methods II (BIOSTAT 704)\nApplied Biostatistical Methods II (BIOSTAT 705)\nIntroduction to the Practice of Biostatistics II (BIOSTAT 706)\nBiostatistics Career Preparation and Development I (BIOSTAT 801)\nSoftware Tools for Data Science (BIOSTAT 821)\n\n(Note: This website was created after this semester was completed, so projects may not have been uploaded yet)\n\n\n\n\nStatistical Methods for Learning and Discovery (BIOSTAT 707)\nGeneralized Linear Models (BIOSTAT 719)\nStatistical Programming for Big Data (BIOSTAT 823)\n\n(Note: This semester is in progress)\n\n\n\n\nLongitudinal and Correlated Data Analysis (BIOSTAT 718)\nIntroduction to Applied Bayesian Analysis (BIOSTAT 724)\nSpecial Topics in Biomedical Engineering: Spatial Omics (BME 590)\nComputational Sequence Biology (CBB 561)\n\n(Note: This semester has not yet started)\nThis is Austin Allen’s website for his Duke MB Program Projects. Looking for Austin’s personal website? Navigate here."
  },
  {
    "objectID": "index.html#fall-2023",
    "href": "index.html#fall-2023",
    "title": "Austin’s MB Projects",
    "section": "",
    "text": "Introduction to Statistical Theory and Methods I (BIOSTAT 701)\nApplied Biostatistical Methods I (BIOSTAT 702)\nIntroduction to the Practice of Biostatistics I (BIOSTAT 703)\nBiostatistics Career Preparation and Development I (BIOSTAT 801)\nProgramming, Data Structures, and Algorithms in C++ (ECE 551D)\n\n(Note: This website was created after this semester was completed, so projects may not have been uploaded yet)"
  },
  {
    "objectID": "index.html#spring-2024",
    "href": "index.html#spring-2024",
    "title": "Austin’s MB Projects",
    "section": "",
    "text": "Introduction to Statistical Theory and Methods II (BIOSTAT 704)\nApplied Biostatistical Methods II (BIOSTAT 705)\nIntroduction to the Practice of Biostatistics II (BIOSTAT 706)\nBiostatistics Career Preparation and Development I (BIOSTAT 801)\nSoftware Tools for Data Science (BIOSTAT 821)\n\n(Note: This website was created after this semester was completed, so projects may not have been uploaded yet)"
  },
  {
    "objectID": "index.html#fall-2024",
    "href": "index.html#fall-2024",
    "title": "Austin’s MB Projects",
    "section": "",
    "text": "Statistical Methods for Learning and Discovery (BIOSTAT 707)\nGeneralized Linear Models (BIOSTAT 719)\nStatistical Programming for Big Data (BIOSTAT 823)\n\n(Note: This semester is in progress)"
  },
  {
    "objectID": "index.html#spring-2025",
    "href": "index.html#spring-2025",
    "title": "Austin’s MB Projects",
    "section": "",
    "text": "Longitudinal and Correlated Data Analysis (BIOSTAT 718)\nIntroduction to Applied Bayesian Analysis (BIOSTAT 724)\nSpecial Topics in Biomedical Engineering: Spatial Omics (BME 590)\nComputational Sequence Biology (CBB 561)\n\n(Note: This semester has not yet started)\nThis is Austin Allen’s website for his Duke MB Program Projects. Looking for Austin’s personal website? Navigate here."
  },
  {
    "objectID": "fall_24/b823/notes/notes.html",
    "href": "fall_24/b823/notes/notes.html",
    "title": "Course Notes for Statistical Methods for Learning and Discovery",
    "section": "",
    "text": "September\n\nWeek of September 3, 2024 - September 5, 2024\n\n\n\nOctober\n\n\nNovember"
  },
  {
    "objectID": "fall_24/b719/projects/hw_1.html",
    "href": "fall_24/b719/projects/hw_1.html",
    "title": "BIOSTAT 719 - Homework 1",
    "section": "",
    "text": "(6 points) [Textbook Exercise 1.6]\n\nThe data in Table 1.4 are the numbers of females and males in the progeny of 16 female light brown apple moths in Muswellbrook, New South Wales, Australia (from Lewis 1987).\n\n\n\n\n\n\n\n\n\n\n\nProgeny Group\nFemales\nMales\n\n\n\n\n1\n18\n11\n\n\n2\n31\n22\n\n\n3\n34\n27\n\n\n4\n33\n29\n\n\n5\n27\n24\n\n\n6\n33\n29\n\n\n7\n28\n25\n\n\n8\n23\n26\n\n\n9\n33\n38\n\n\n10\n12\n14\n\n\n11\n19\n23\n\n\n12\n25\n31\n\n\n13\n14\n20\n\n\n14\n4\n6\n\n\n15\n22\n34\n\n\n16\n7\n12\n\n\n\n\n\n\nLet \\(Y_i\\) denote the number of females in each of the 16 groups of progeny in each group (\\(i = 1, ..., 16\\)). Suppose the \\(Y_i\\)’s are independent random variables each with the Binomial distribution\n\n\\[\nf(y_i; \\theta) = {n_i \\choose y_i}\\theta^{y_i}(1 - \\theta)^{n_i - y_i}\n\\]\n\nFind the maximum likelihood estimator (MLE) of \\(\\theta\\) using calculus and evaluate it for these data.\n\nLet’s first find the MLE using calculus. Let’s review the steps:\n\nCalculate the log-likelihood function\nTake the first derivative of the log-likelihood function (this is the ‘score’ function)\nSet the score function equal to 0 and solve for \\(\\hat{\\theta}\\)\nTake the second derivative of the function to determine whether the function is concave down (i.e. has a maximum value at \\(\\hat{\\theta}\\))\n\nWith that in mind, let’s jump in!\n\\[\\begin{align*}\n\\ell (\\theta_i ; y_i) &= \\sum_{i = 1}^{16} \\log\\left( f(y_i; \\theta) \\right)\\\\\n&= \\sum_{i = 1}^{16} \\log\\left[ {n_i \\choose y_i}\\theta^{y_i}(1 - \\theta)^{n_i - y_i}  \\right]\\\\\n&= \\sum_{i = 1}^{16} \\log {n_i \\choose y_i} + \\log(\\theta)\\sum_{i = 1}^{16} y_i + log(1 - \\theta)\\sum_{i = 1}^{16}(n_i - y_i)  \\\\\n\\frac{d \\ell}{d\\theta} &= 0 + \\sum_{i = 1}^{16} \\frac{y_i}{\\theta} - \\frac{\\sum_{i = 1}^{16} n_i - \\sum_{i = 1}^{16} y_i}{1 - \\theta} \\\\\n\\underline{\\text{set}} \\quad 0 &=  \\sum_{i = 1}^{16} \\frac{y_i}{\\hat{\\theta}} - \\frac{\\sum_{i = 1}^{16} n_i - \\sum_{i = 1}^{16} y_i}{1 - \\hat{\\theta}} \\\\\n\\implies \\sum_{i = 1}^{16} \\frac{y_i}{\\hat{\\theta}} &= \\frac{\\sum_{i = 1}^{16} n_i - \\sum_{i = 1}^{16} y_i}{1 - \\hat{\\theta}} \\\\\n\\implies  \\hat{\\theta} \\sum_{i = 1}^{16} n_i &= \\sum_{i = 1}^{16} y_i \\\\\n\\implies \\hat{\\theta} &= \\frac{1}{\\sum_{i = 1}^{16} n_i} \\sum_{i = 1}^{16} y_i\n\\end{align*}\\]\nTo verify whether this is an MLE or not, let’s now complete step 4 and take the second derivative of the log-likelihood function to see whether it is concave down at \\(\\hat{\\theta}\\).\n\\[\\begin{align*}\n\\frac{d^2\\ell}{d\\theta^2} &= -\\sum_{i = 1}^{16} \\frac{y_i}{\\theta^2} - \\frac{\\sum_{i = 1}^{16} n_i - \\sum_{i = 1}^{16} y_i}{(1 - \\theta)^2}\n\\end{align*}\\]\nNote that because \\(0 \\le \\theta \\le 1\\), and because \\(y = 0, 1, 2, ...\\), and because \\(n = 1, 2, 3, ...\\), the second derivative of the log-likelihood function will be negative for all values of \\(\\theta\\). That means that the first derivative has a maximum at \\(\\hat{\\theta}\\).\nThus, the MLE for a random sample of size 16 is \\(\\hat{\\theta} = \\frac{1}{\\sum_{i = 1}^{16} n_i} \\sum_{i = 1}^{16} y_i\\). Intuitively, this makes sense, because this is essentially the total number of females in all progenies divided by the total number of individuals. This value for \\(\\hat{\\theta}\\) is evaluated to be \\(363/(371+363) = 0.49\\)."
  },
  {
    "objectID": "fall_24/b719/projects/hw_1.html#problem-1",
    "href": "fall_24/b719/projects/hw_1.html#problem-1",
    "title": "BIOSTAT 719 - Homework 1",
    "section": "",
    "text": "(6 points) [Textbook Exercise 1.6]\n\nThe data in Table 1.4 are the numbers of females and males in the progeny of 16 female light brown apple moths in Muswellbrook, New South Wales, Australia (from Lewis 1987).\n\n\n\n\n\n\n\n\n\n\n\nProgeny Group\nFemales\nMales\n\n\n\n\n1\n18\n11\n\n\n2\n31\n22\n\n\n3\n34\n27\n\n\n4\n33\n29\n\n\n5\n27\n24\n\n\n6\n33\n29\n\n\n7\n28\n25\n\n\n8\n23\n26\n\n\n9\n33\n38\n\n\n10\n12\n14\n\n\n11\n19\n23\n\n\n12\n25\n31\n\n\n13\n14\n20\n\n\n14\n4\n6\n\n\n15\n22\n34\n\n\n16\n7\n12\n\n\n\n\n\n\nLet \\(Y_i\\) denote the number of females in each of the 16 groups of progeny in each group (\\(i = 1, ..., 16\\)). Suppose the \\(Y_i\\)’s are independent random variables each with the Binomial distribution\n\n\\[\nf(y_i; \\theta) = {n_i \\choose y_i}\\theta^{y_i}(1 - \\theta)^{n_i - y_i}\n\\]\n\nFind the maximum likelihood estimator (MLE) of \\(\\theta\\) using calculus and evaluate it for these data.\n\nLet’s first find the MLE using calculus. Let’s review the steps:\n\nCalculate the log-likelihood function\nTake the first derivative of the log-likelihood function (this is the ‘score’ function)\nSet the score function equal to 0 and solve for \\(\\hat{\\theta}\\)\nTake the second derivative of the function to determine whether the function is concave down (i.e. has a maximum value at \\(\\hat{\\theta}\\))\n\nWith that in mind, let’s jump in!\n\\[\\begin{align*}\n\\ell (\\theta_i ; y_i) &= \\sum_{i = 1}^{16} \\log\\left( f(y_i; \\theta) \\right)\\\\\n&= \\sum_{i = 1}^{16} \\log\\left[ {n_i \\choose y_i}\\theta^{y_i}(1 - \\theta)^{n_i - y_i}  \\right]\\\\\n&= \\sum_{i = 1}^{16} \\log {n_i \\choose y_i} + \\log(\\theta)\\sum_{i = 1}^{16} y_i + log(1 - \\theta)\\sum_{i = 1}^{16}(n_i - y_i)  \\\\\n\\frac{d \\ell}{d\\theta} &= 0 + \\sum_{i = 1}^{16} \\frac{y_i}{\\theta} - \\frac{\\sum_{i = 1}^{16} n_i - \\sum_{i = 1}^{16} y_i}{1 - \\theta} \\\\\n\\underline{\\text{set}} \\quad 0 &=  \\sum_{i = 1}^{16} \\frac{y_i}{\\hat{\\theta}} - \\frac{\\sum_{i = 1}^{16} n_i - \\sum_{i = 1}^{16} y_i}{1 - \\hat{\\theta}} \\\\\n\\implies \\sum_{i = 1}^{16} \\frac{y_i}{\\hat{\\theta}} &= \\frac{\\sum_{i = 1}^{16} n_i - \\sum_{i = 1}^{16} y_i}{1 - \\hat{\\theta}} \\\\\n\\implies  \\hat{\\theta} \\sum_{i = 1}^{16} n_i &= \\sum_{i = 1}^{16} y_i \\\\\n\\implies \\hat{\\theta} &= \\frac{1}{\\sum_{i = 1}^{16} n_i} \\sum_{i = 1}^{16} y_i\n\\end{align*}\\]\nTo verify whether this is an MLE or not, let’s now complete step 4 and take the second derivative of the log-likelihood function to see whether it is concave down at \\(\\hat{\\theta}\\).\n\\[\\begin{align*}\n\\frac{d^2\\ell}{d\\theta^2} &= -\\sum_{i = 1}^{16} \\frac{y_i}{\\theta^2} - \\frac{\\sum_{i = 1}^{16} n_i - \\sum_{i = 1}^{16} y_i}{(1 - \\theta)^2}\n\\end{align*}\\]\nNote that because \\(0 \\le \\theta \\le 1\\), and because \\(y = 0, 1, 2, ...\\), and because \\(n = 1, 2, 3, ...\\), the second derivative of the log-likelihood function will be negative for all values of \\(\\theta\\). That means that the first derivative has a maximum at \\(\\hat{\\theta}\\).\nThus, the MLE for a random sample of size 16 is \\(\\hat{\\theta} = \\frac{1}{\\sum_{i = 1}^{16} n_i} \\sum_{i = 1}^{16} y_i\\). Intuitively, this makes sense, because this is essentially the total number of females in all progenies divided by the total number of individuals. This value for \\(\\hat{\\theta}\\) is evaluated to be \\(363/(371+363) = 0.49\\)."
  },
  {
    "objectID": "fall_24/b719/projects/hw_1.html#problem-2",
    "href": "fall_24/b719/projects/hw_1.html#problem-2",
    "title": "BIOSTAT 719 - Homework 1",
    "section": "Problem 2",
    "text": "Problem 2\n(12 points)\n\nLet \\(Y_i, ... , Y_n\\) be independent random variables from the exponential distribution\n\n\\[\nf(y_i; \\lambda) = \\lambda e^{-\\lambda y_i}, \\quad y_i &gt; 0, \\lambda &gt; 0\n\\]\nPart (a):\n\nWhat is the maximum likelihood estimator (MLE) of \\(\\lambda\\)? Show all the derivation details.\n\nLet’s follow the same four steps to find this out!\n\\[\\begin{align*}\n\\ell(\\lambda) &= \\sum_{i = 1}^n \\log [f(y; \\lambda)]\\\\\n&= \\sum_{i = 1}^n \\log [\\lambda e^{-\\lambda y_i}]\\\\\n&= \\sum_{i = 1}^n \\log (\\lambda) - \\sum_{i = 1}^n\\lambda y_i\\\\\n&= n \\log (\\lambda) - \\sum_{i = 1}^n\\lambda y_i\\\\\n\\frac{d\\ell}{d\\lambda} &= \\frac{n}{\\lambda} - \\sum_{i = 1}^n y_i\\\\\n\\underline{\\text{set}}\\quad 0 &= \\frac{n}{\\hat{\\lambda}} - \\sum_{i = 1}^n y_i\\\\\n\\implies \\frac{n}{\\hat{\\lambda}} &= \\sum_{i = 1}^n y_i\\\\\n\\implies \\hat{\\lambda} &= \\frac{n}{\\sum_{i = 1}^n y_i}\\\\\n\\implies \\hat{\\lambda} &= \\frac{1}{\\bar{Y}}\n\\end{align*}\\]\nThis is a fun result, especially considering the fact that the rate parameter is the inverse of the scale parameter. So, by the invariance property of MLEs, we know that the MLE for \\(\\theta\\) (the scale parameter) is \\(\\bar{Y}\\).\nPart (b):\n\nSuppose \\(\\lambda = e^{\\beta}\\). Find the MLE of \\(\\beta\\).\n\nWe are given that \\(\\lambda = e^{\\beta}\\). Thus, \\(\\beta = \\log{\\lambda}\\). By the invariance property of MLEs, if \\(g(\\lambda)\\) is a function of \\(\\lambda\\), then the MLE of \\(g(\\theta)\\) is \\(g(\\hat{\\theta})\\).\nLet \\(g(\\theta) = \\log(\\lambda) = \\beta\\). \\(g(\\hat{\\lambda}) = \\log\\left( \\frac{1}{\\bar{Y}}\\right)\\), which is the MLE of \\(\\beta\\).\nPart (c):\n\nConsider 150 observations \\(y_i, (i = 1, 2, ..., 150)\\) from the exponential distribution with the sum of the 150 observations equal to 30. What is the numerical evaluation of the MLE of \\(\\lambda\\) and \\(\\beta\\)?\n\nEasy peasy. We did all the hard stuff already, so it’s just plug and chug time!\nFor \\(\\hat{\\lambda}\\):\n\\[\\begin{align*}\n\\hat{\\lambda} &= \\frac{1}{\\bar{Y}}\\\\\n&= \\frac{1}{\\frac{30}{150}}\\\\\n&= 5\n\\end{align*}\\]\nFor \\(\\hat{\\beta}\\):\n\\[\\begin{align*}\n\\hat{\\beta} &= \\log\\left[\\frac{1}{\\bar{Y}}\\right]\\\\\n&= \\log(5)\n\\end{align*}\\]"
  },
  {
    "objectID": "fall_24/b719/notes/notes.html",
    "href": "fall_24/b719/notes/notes.html",
    "title": "Generalized Linear Models: Course Notes",
    "section": "",
    "text": "August\n\nWeek of August 27, 2024 - August 29, 2024\n\n\n\nSeptember\n\nWeek of September 3, 2024 - September 5, 2024\n\n\n\nOctober\n\n\nNovember\nBack"
  },
  {
    "objectID": "fall_24/b719/index.html",
    "href": "fall_24/b719/index.html",
    "title": "Generalized Linear Models: Class Projects",
    "section": "",
    "text": "August\n\nHomework 1\n\n\n\nSeptember\n\n\nOctober\n\n\nNovember\nTo review notes taken during class, follow this link.\nBack"
  },
  {
    "objectID": "fall_24/b707/notes/notes.html",
    "href": "fall_24/b707/notes/notes.html",
    "title": "Course Notes for Statistical Methods for Learning and Discovery",
    "section": "",
    "text": "August\n\nWeek of August 26, 2024 - August 28, 2024\n\n\n\nSeptember\n\nWeek of September 4, 2024\n\n\n\nOctober\n\n\nNovember\nBack"
  },
  {
    "objectID": "fall_24/b707/index.html",
    "href": "fall_24/b707/index.html",
    "title": "Statistical Methods for Learning and Discovery",
    "section": "",
    "text": "September\n\n\nOctober\n\n\nNovember\nTo review notes taken during class, follow this link.\nBack"
  },
  {
    "objectID": "fall_24/b707/bsenv/Lib/site-packages/pyzmq-26.2.0.dist-info/licenses/LICENSE.html",
    "href": "fall_24/b707/bsenv/Lib/site-packages/pyzmq-26.2.0.dist-info/licenses/LICENSE.html",
    "title": "Austin's MB Projects",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2009-2012, Brian Granger, Min Ragan-Kelley\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "fall_24/b707/bsenv/Lib/site-packages/numpy/random/LICENSE.html",
    "href": "fall_24/b707/bsenv/Lib/site-packages/numpy/random/LICENSE.html",
    "title": "NCSA Open Source License",
    "section": "",
    "text": "This software is dual-licensed under the The University of Illinois/NCSA Open Source License (NCSA) and The 3-Clause BSD License\n\nNCSA Open Source License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nDeveloped by: Kevin Sheppard (kevin.sheppard@economics.ox.ac.uk, kevin.k.sheppard@gmail.com) http://www.kevinsheppard.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution.\nNeither the names of Kevin Sheppard, nor the names of any contributors may be used to endorse or promote products derived from this Software without specific prior written permission.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE.\n\n\n3-Clause BSD License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nComponents\nMany parts of this module have been derived from original sources, often the algorithm’s designer. Component licenses are located with the component code."
  },
  {
    "objectID": "fall_24/b707/bsenv/Lib/site-packages/httpx-0.27.2.dist-info/licenses/LICENSE.html",
    "href": "fall_24/b707/bsenv/Lib/site-packages/httpx-0.27.2.dist-info/licenses/LICENSE.html",
    "title": "Austin's MB Projects",
    "section": "",
    "text": "Copyright © 2019, Encode OSS Ltd. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Austin’s MB Projects",
    "section": "",
    "text": "This website was created by Austin Allen. All projects shown here were completed during his time in the Master of Biostatistics (MB) Program at Duke University. Projects are organized by course.\nWhile these projects were assigned by instructors and were completed between August 2023 and May 2025, you can check out Austin’s personal website to see projects selected by him to demonstrate skills as well as to have a little fun."
  },
  {
    "objectID": "fall_24/b707/bsenv/Lib/site-packages/httpcore-1.0.5.dist-info/licenses/LICENSE.html",
    "href": "fall_24/b707/bsenv/Lib/site-packages/httpcore-1.0.5.dist-info/licenses/LICENSE.html",
    "title": "Austin's MB Projects",
    "section": "",
    "text": "Copyright © 2020, Encode OSS Ltd. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "fall_24/b707/bsenv/Lib/site-packages/idna-3.8.dist-info/LICENSE.html",
    "href": "fall_24/b707/bsenv/Lib/site-packages/idna-3.8.dist-info/LICENSE.html",
    "title": "Austin's MB Projects",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2013-2024, Kim Davies and contributors. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "fall_24/b707/bsenv/Lib/site-packages/soupsieve-2.6.dist-info/licenses/LICENSE.html",
    "href": "fall_24/b707/bsenv/Lib/site-packages/soupsieve-2.6.dist-info/licenses/LICENSE.html",
    "title": "Austin's MB Projects",
    "section": "",
    "text": "MIT License\nCopyright (c) 2018 - 2024 Isaac Muse isaacmuse@gmail.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "fall_24/b707/notes/august/aug_26.html",
    "href": "fall_24/b707/notes/august/aug_26.html",
    "title": "August 26, 2024 - August 28, 2024",
    "section": "",
    "text": "Prediction and inference.\n\nWe care about both. How do we manage that “tug-of-war”?\n\nParametric vs Non-parametric\n\nParametric models are conveniently powerful, but they require assumptions to be met.\nNon-parametric models are convenient in that they do not require assumptions to be met, but the trade off is power\n\nAccuracy vs Interpretability\n\nChuang showed a diagram of several tools we’re familiar with on a plot with “Interpretability” on the Y-axis and “Flexibility” on the X-axis. On the far end (high flexibility, low interpretability) were support vector machines. On the near end (high interpretability, low flexibility) was LASSO. Several others were somewhere in the middle.\n\n\n\n\n\n\nCreate reproducible reports\nCreate high-quality graphs\nExplore a new dataset\nBuild a predictive model\n\n\n\n\n\nThe first day of class, Chuang showed a diagram of several tools we’re familiar with on a plot with “Interpretability” on the Y-axis and “Flexibility” on the X-axis. What was on the near end of the spectrum (high interpretability, low flexibility)? What was on the far end of the spectrum (high interpretability, low flexibility)?\nWhat are the four goals for this semester?\nDescribe the trade-off between power and flexibiliy in the context of parametric and non-parametric models."
  },
  {
    "objectID": "fall_24/b707/notes/august/aug_26.html#trade-offs",
    "href": "fall_24/b707/notes/august/aug_26.html#trade-offs",
    "title": "August 26, 2024 - August 28, 2024",
    "section": "",
    "text": "Prediction and inference.\n\nWe care about both. How do we manage that “tug-of-war”?\n\nParametric vs Non-parametric\n\nParametric models are conveniently powerful, but they require assumptions to be met.\nNon-parametric models are convenient in that they do not require assumptions to be met, but the trade off is power\n\nAccuracy vs Interpretability\n\nChuang showed a diagram of several tools we’re familiar with on a plot with “Interpretability” on the Y-axis and “Flexibility” on the X-axis. On the far end (high flexibility, low interpretability) were support vector machines. On the near end (high interpretability, low flexibility) was LASSO. Several others were somewhere in the middle."
  },
  {
    "objectID": "fall_24/b707/notes/august/aug_26.html#goals-by-the-end-of-the-semester",
    "href": "fall_24/b707/notes/august/aug_26.html#goals-by-the-end-of-the-semester",
    "title": "August 26, 2024 - August 28, 2024",
    "section": "",
    "text": "Create reproducible reports\nCreate high-quality graphs\nExplore a new dataset\nBuild a predictive model"
  },
  {
    "objectID": "fall_24/b707/notes/august/aug_26.html#three-take-aways",
    "href": "fall_24/b707/notes/august/aug_26.html#three-take-aways",
    "title": "August 26, 2024 - August 28, 2024",
    "section": "",
    "text": "The first day of class, Chuang showed a diagram of several tools we’re familiar with on a plot with “Interpretability” on the Y-axis and “Flexibility” on the X-axis. What was on the near end of the spectrum (high interpretability, low flexibility)? What was on the far end of the spectrum (high interpretability, low flexibility)?\nWhat are the four goals for this semester?\nDescribe the trade-off between power and flexibiliy in the context of parametric and non-parametric models."
  },
  {
    "objectID": "fall_24/b707/notes/august/aug_26.html#reproducible-research",
    "href": "fall_24/b707/notes/august/aug_26.html#reproducible-research",
    "title": "August 26, 2024 - August 28, 2024",
    "section": "Reproducible Research",
    "text": "Reproducible Research\n\nSteps in Research\n\nSpecify the population\nState the research question\nFormulate the hypothesis\nDesign the experiment\nSpecify the experimentor\nSpecify the data collection process\nCreate an analysis plan\nSpecify the analyst\nWrite the code\nEstimate the truth\nMake claims\n\n\n\nImportant concepts of a scientific study\n\nPublications\nReproducible: Given same data, plan, code, etc. obtain the exact results\nReplicable: Given the same population, hypothesis and design, obtain similar results\nFalse discovery: The claim at the end of a study is not equal to the claim you would make if you could observe all data from the population, given your hypothesis, study design, and analysis plan\nP-hacking: Given a population, hypothesis, design, data, plan and analysis, the code changes to match the desired statement\nFile drawer effect: The probability of publication depends on the caim made at the conclusion of a scientific study\n\n\n\nReproducibility Do’s and Don’ts\n\nDo:\n\nIdentify source data\nAutomate process\nDocument code\nUse version control\nTrack software environment\nSet random number generator\nConsider full pipeline\n\nDon’t:\n\nOnly save output\nDo things by hand\nPoint and click"
  },
  {
    "objectID": "fall_24/b707/notes/august/aug_26.html#three-take-aways-1",
    "href": "fall_24/b707/notes/august/aug_26.html#three-take-aways-1",
    "title": "August 26, 2024 - August 28, 2024",
    "section": "Three Take-aways",
    "text": "Three Take-aways\n\nThe claim at the end of a study is not equal to the claim you would make if you could observe all data from the population, given your hypothesis, study design, and analysis plan. What is this?\nGiven a population, hypothesis, design, data, plan and analysis, the code changes to match the desired statement. What is this?\nThe probability of publication depends on the caim made at the conclusion of a scientific study. What is this?\n\nBack"
  },
  {
    "objectID": "fall_24/b707/notes/september/sep_4.html",
    "href": "fall_24/b707/notes/september/sep_4.html",
    "title": "September 4, 2024",
    "section": "",
    "text": "What’s the difference between the joins? Left, right, inner, outer, and full - not to mention the option to exclude A from B, etc.\nWhat’s the difference between merge and join?\n\nMerge loses the order of observations\n\n\n\n\n\n\n\n\nCentral tendancy\n\nMean, median, mode\n\nVariability\n\nStandard deviation, IQR\n\nSkewness\n\n\n\n\n\nCorrelation\n\nWhat’s the difference between Pearson’s \\(r\\), Spearman’s \\(\\rho\\), and Kendall’s \\(\\tau\\)?\n\nPearson’s \\(r\\) is parametric\nSpearman’s \\(\\rho\\) is non-parametric and is rank-based\nKendall’s \\(\\tau\\) is non-parametric and can handle categorical variables\n\n\nVariability by group\nTrajectory\n\nSlope\n\n\n\n\n\n\n\n\n\nUnivariate non-response\n\nSingle variable missing data\n\nMultivariate two patterns\n\nI think this is when there are two patterns in the data. Some variables have no missing data, and other variables have missing data in the same places\n\nMonotone\n\nThis is when missingness is exacerbated with variables. For example, let’s say we yave X1, X2, and X3. X1 is missing values, and because X2 and X3 depend on X1, any missingness in X1 is also present in X2 and X3. Then suppose X3 depends on X2, any missingness in X2 shows up in X3 as well. Finally, X3 may have its own missing values. What we get is a steady increase in missingness from X1 to X2 and X3.\n\n\nGeneral\n\nNo patterns are evidence\n\nFile matching\n\nA good example is in a full join of two datasets. Suppose one dataset had variable A and the other had variable B, and both datasets had unique individuals. We will observe a pattern where there is no common missingness for A and B, nor will there be any individual who has both A and B present.\n\nFactor analysis\n\nThis is when there is an entire variable is missing\n\n\n\n\n\n\nMissing Completely At Random (MCAR)\n\n\\(E(Y^c) = E(Y^O)\\)\nA patient is scheduled for a visit but breaks his arms while skiing\nApproach: use complete case (exclude missing values)\n\nMissing At Random (MAR)\n\n\\(E(Y^c) = E(Y^O | X^O)\\)\nA patient is scheduled for a visit but does not come because he is sick; the sickness is recorded\nApproach: multiple imputation\n\nMissing Not At Random (MNAR)\n\n\\(E(Y^c) \\ne E(Y^O | X^O)\\)\nA patient is scheduled for a visit but does not come because he is sick; the sickness is NOT recorded\nApproach: Model-based correction\n\n\n\n\n\n\n\nWhich non-parametric test of correlation can handle categorical variables?\nIf values are missing completely at random (MCAR), what should your approach be?\nIf values are missing at random (MAR), what should your approach be?\n\nBack"
  },
  {
    "objectID": "fall_24/b707/notes/september/sep_4.html#coding-concepts",
    "href": "fall_24/b707/notes/september/sep_4.html#coding-concepts",
    "title": "September 4, 2024",
    "section": "",
    "text": "What’s the difference between the joins? Left, right, inner, outer, and full - not to mention the option to exclude A from B, etc.\nWhat’s the difference between merge and join?\n\nMerge loses the order of observations"
  },
  {
    "objectID": "fall_24/b707/notes/september/sep_4.html#describing-variables",
    "href": "fall_24/b707/notes/september/sep_4.html#describing-variables",
    "title": "September 4, 2024",
    "section": "",
    "text": "Central tendancy\n\nMean, median, mode\n\nVariability\n\nStandard deviation, IQR\n\nSkewness\n\n\n\n\n\nCorrelation\n\nWhat’s the difference between Pearson’s \\(r\\), Spearman’s \\(\\rho\\), and Kendall’s \\(\\tau\\)?\n\nPearson’s \\(r\\) is parametric\nSpearman’s \\(\\rho\\) is non-parametric and is rank-based\nKendall’s \\(\\tau\\) is non-parametric and can handle categorical variables\n\n\nVariability by group\nTrajectory\n\nSlope"
  },
  {
    "objectID": "fall_24/b707/notes/september/sep_4.html#missing-data",
    "href": "fall_24/b707/notes/september/sep_4.html#missing-data",
    "title": "September 4, 2024",
    "section": "",
    "text": "Univariate non-response\n\nSingle variable missing data\n\nMultivariate two patterns\n\nI think this is when there are two patterns in the data. Some variables have no missing data, and other variables have missing data in the same places\n\nMonotone\n\nThis is when missingness is exacerbated with variables. For example, let’s say we yave X1, X2, and X3. X1 is missing values, and because X2 and X3 depend on X1, any missingness in X1 is also present in X2 and X3. Then suppose X3 depends on X2, any missingness in X2 shows up in X3 as well. Finally, X3 may have its own missing values. What we get is a steady increase in missingness from X1 to X2 and X3.\n\n\nGeneral\n\nNo patterns are evidence\n\nFile matching\n\nA good example is in a full join of two datasets. Suppose one dataset had variable A and the other had variable B, and both datasets had unique individuals. We will observe a pattern where there is no common missingness for A and B, nor will there be any individual who has both A and B present.\n\nFactor analysis\n\nThis is when there is an entire variable is missing\n\n\n\n\n\n\nMissing Completely At Random (MCAR)\n\n\\(E(Y^c) = E(Y^O)\\)\nA patient is scheduled for a visit but breaks his arms while skiing\nApproach: use complete case (exclude missing values)\n\nMissing At Random (MAR)\n\n\\(E(Y^c) = E(Y^O | X^O)\\)\nA patient is scheduled for a visit but does not come because he is sick; the sickness is recorded\nApproach: multiple imputation\n\nMissing Not At Random (MNAR)\n\n\\(E(Y^c) \\ne E(Y^O | X^O)\\)\nA patient is scheduled for a visit but does not come because he is sick; the sickness is NOT recorded\nApproach: Model-based correction"
  },
  {
    "objectID": "fall_24/b707/notes/september/sep_4.html#three-take-aways",
    "href": "fall_24/b707/notes/september/sep_4.html#three-take-aways",
    "title": "September 4, 2024",
    "section": "",
    "text": "Which non-parametric test of correlation can handle categorical variables?\nIf values are missing completely at random (MCAR), what should your approach be?\nIf values are missing at random (MAR), what should your approach be?\n\nBack"
  },
  {
    "objectID": "fall_24/b719/notes/august/aug_27.html",
    "href": "fall_24/b719/notes/august/aug_27.html",
    "title": "August 27, 2024 - August 29, 2024",
    "section": "",
    "text": "The textbook for this course is “An Introduction to Generalized Linear Models, Fourth Edition” by Chapman and Hall.\nShe uses R and SAS.\nCourse grading scale:\n\nAttendance and pop quiz: 5%\nHomework: 20%\nMidterm: 25%\nFinal: 30%\nGroup Research Project: 20%\n\nHomework\n\nThere will be 9 weekly homework assignments. Each are due at the beginning of the class on the due day.\nSubmit as a PDF document.\n10% deduction in score for late submissions.\n\nExams\n\nMidterm and final exams will be in-class.\nThere is a one-page cheat sheet allowed (double-sided).\nRules for exams:\n\nOnly bring calculator (non-graphing) and pencil + eraser\nExams are proctored.\n\n\nGroup research project\n\nWill require analysis of a data set, final report, and final presentation.\n\nPop quizzes\n\nThe primary purpose of the pop quiz is to check attendance.\n\nCommunications\n\nTeams channel in MS Teams\n\nAI Policies\n\nAI is allowed. However, be transparent about use.\nFact checking is my own responsibility.\nAI-generated content without proper acknowledgement or references will be treated as plagiarism.\n\n\n\n\n\n\n\n\nHere’s the Syllabus\n\n\n\n\n\n\n\n\n\n\n\n\n\nTake ownership of your projects. This is one of the hardest things to teach to students.\nMake a check-list for all that needs to be done in all the analyses you come across.\nHwanhee once met an incredibly driven student that was studying in her program while simultaneously working on a part-time PhD program and conducting government research in Korea. But even with his full plate, he took meticulous notes during each class period and would pester her about the lectures. She said that she was annoyed at him and asked him why he cared so much. He responded, “This is my last chance to go through this course material. I won’t get another chance, and I have to learn this now.”"
  },
  {
    "objectID": "fall_24/b719/notes/august/aug_27.html#syllabus",
    "href": "fall_24/b719/notes/august/aug_27.html#syllabus",
    "title": "August 27, 2024 - August 29, 2024",
    "section": "",
    "text": "The textbook for this course is “An Introduction to Generalized Linear Models, Fourth Edition” by Chapman and Hall.\nShe uses R and SAS.\nCourse grading scale:\n\nAttendance and pop quiz: 5%\nHomework: 20%\nMidterm: 25%\nFinal: 30%\nGroup Research Project: 20%\n\nHomework\n\nThere will be 9 weekly homework assignments. Each are due at the beginning of the class on the due day.\nSubmit as a PDF document.\n10% deduction in score for late submissions.\n\nExams\n\nMidterm and final exams will be in-class.\nThere is a one-page cheat sheet allowed (double-sided).\nRules for exams:\n\nOnly bring calculator (non-graphing) and pencil + eraser\nExams are proctored.\n\n\nGroup research project\n\nWill require analysis of a data set, final report, and final presentation.\n\nPop quizzes\n\nThe primary purpose of the pop quiz is to check attendance.\n\nCommunications\n\nTeams channel in MS Teams\n\nAI Policies\n\nAI is allowed. However, be transparent about use.\nFact checking is my own responsibility.\nAI-generated content without proper acknowledgement or references will be treated as plagiarism.\n\n\n\n\n\n\n\n\nHere’s the Syllabus"
  },
  {
    "objectID": "fall_24/b719/notes/august/aug_27.html#three-take-aways",
    "href": "fall_24/b719/notes/august/aug_27.html#three-take-aways",
    "title": "August 27, 2024 - August 29, 2024",
    "section": "",
    "text": "Take ownership of your projects. This is one of the hardest things to teach to students.\nMake a check-list for all that needs to be done in all the analyses you come across.\nHwanhee once met an incredibly driven student that was studying in her program while simultaneously working on a part-time PhD program and conducting government research in Korea. But even with his full plate, he took meticulous notes during each class period and would pester her about the lectures. She said that she was annoyed at him and asked him why he cared so much. He responded, “This is my last chance to go through this course material. I won’t get another chance, and I have to learn this now.”"
  },
  {
    "objectID": "fall_24/b719/notes/august/aug_27.html#review-of-linear-regression-concepts",
    "href": "fall_24/b719/notes/august/aug_27.html#review-of-linear-regression-concepts",
    "title": "August 27, 2024 - August 29, 2024",
    "section": "Review of Linear Regression Concepts",
    "text": "Review of Linear Regression Concepts\n\nSay we have two variables, X and Y (predictor and response). Y (the response or outcome) is regarded as a random variable. Explanatory variables (X) are treated as fixed by the experimental design.\nTypes of outcomes:\n\nContinous (e.g. BMI, SBP) - linear regression\nBinary (e.g. death \\(\\in\\) {1, 0}) - logistic regression\nCategorical (nominal, ordinal) - nominal/ordinal logistic regression\nCounts (e.g. number of hospitalizations) - Poisson regression"
  },
  {
    "objectID": "fall_24/b719/notes/august/aug_27.html#likelihood-and-mles",
    "href": "fall_24/b719/notes/august/aug_27.html#likelihood-and-mles",
    "title": "August 27, 2024 - August 29, 2024",
    "section": "Likelihood and MLEs",
    "text": "Likelihood and MLEs\n\n\\(f(y; \\theta)\\) is a probability distribution, where \\(\\theta\\) represents the parameters of the distribution\n\\(L(\\theta; y)\\) is a likelihood function: \\(L(\\theta; y) = \\prod_{i = 1}^n f(y; \\theta)\\)\n\\(l(\\theta; y)\\) is the log likelihood function: \\(l(\\theta; y) = \\sum log f(y; \\theta)\\)\nMLE \\(\\hat{\\theta}\\) of parameter $$ is the value which maximizes the likelihood function: \\(L(\\hat{\\theta}; y) \\ge L(\\theta; y)\\), for all \\(\\theta \\in \\Omega\\) (this is also true for the log-likelihood function)\nHow do you get the MLE? Take the derivative of the log-likelihood function, set to 0, and solve. Then take the second derivative and check the sign."
  },
  {
    "objectID": "fall_24/b719/notes/august/aug_27.html#linear-model-specifications",
    "href": "fall_24/b719/notes/august/aug_27.html#linear-model-specifications",
    "title": "August 27, 2024 - August 29, 2024",
    "section": "Linear Model Specifications",
    "text": "Linear Model Specifications\n\nModel Fitting Process:\n\n\nSpecify model\n\nFind the probability distribution of Y (what type of variable? what tests are appropriate? etc.)\nEquation linking response and explanatory variable\n\nEstimation of parameters in the model\ncheck adequacy of model (residuals, deviance, AIC, etc.)\nMake inference - confidence intervals, interpretation of results, hypothesis testing\n\n\nIn class, there was an example with women from the town and country (1, 0) and some sort of response variable (I think it was a count). Hwanhee said that in this case, where we have a factor variable, there are two main ways we can think about Y. First, we can construct our Y vector as a \\(n\\text{ x } 1\\) dimmensional vector. The model formula, then, would look like this: \\(Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon\\), where \\(X_i = \\begin{cases}1, \\quad \\text{From town}\\\\0, \\quad \\text{From city} \\end{cases}\\). The other way to think about this is to construct our \\(Y\\) vector to be \\(j \\text{ x } k\\) dimmensional, where \\(j\\) is the number of levels of our factor variable and \\(k\\) is the number of individuals in group \\(j\\). In this case, the model formula would be \\(Y_{jk} = \\mu + \\alpha_j + \\epsilon_k\\), where \\(\\mu\\) is the mean of the reference group and \\(\\alpha\\) is the difference between the means of the reference group and group \\(j\\)."
  },
  {
    "objectID": "fall_24/b719/notes/august/aug_27.html#three-take-aways-1",
    "href": "fall_24/b719/notes/august/aug_27.html#three-take-aways-1",
    "title": "August 27, 2024 - August 29, 2024",
    "section": "Three Take-aways",
    "text": "Three Take-aways\n\nFor a response and explanatory variable, X is considered fixed and Y is considered a random variable.\nThe four steps for the calculus method for finding an MLE is as follows:\n\nFind the log-likelihood function: \\(\\ell (\\theta | y) = \\sum_{i = 1}^n \\log \\left( f(y; \\theta)\\right)\\)\nTake the derivative\nSet to zero and solve\nTake the second derivative\n\nThe are two primary ways of structuring a model formula with a factor-level variable:\n\n\\(Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i\\), where \\(X\\) is the factor-level variable\n\\(Y_{jk} = \\mu + Z_{jk} \\alpha + epsilon_{jk}\\), where \\(\\mu\\) is the mean of the reference group and \\(\\alpha\\) is the difference in means of the two groups (assuming two groups)\n\n\nBack"
  },
  {
    "objectID": "fall_24/b719/notes/september/sep_3.html",
    "href": "fall_24/b719/notes/september/sep_3.html",
    "title": "September 3, 2024 - September 5, 2024",
    "section": "",
    "text": "When an outcome is continuous, we consider a LR model like to be: \\(E(Y_i) = \\mu_i = X_i^T \\beta\\), where \\(T_i \\sim N(\\mu_i, \\sigma^2)\\)\nFor models with non-continuous outcomes, the distribution of \\(Y_i\\) is not normal. However, they may be in the exponential family and can share some of the nice properties of normality\nExponential family definition:\n\nDistribution of Y belongs to the exponential family if it can be written in the form \\(f(y; \\theta) = exp[a(y)b(\\theta) + c(\\theta) + d(y)]\\)\nCanonical form: if \\(a(y) = y\\), the distribution is in canonical form and \\(b(\\theta)\\) is said to be the natural parameter\nIf there are other parameters other than the parameter of interest (say \\(\\sigma^2\\) when we’re interested in \\(\\mu\\)), these are said to be nuisance parameters\n\n\n\n\n\n\n\n\nIs the Poisson PDF in canonical form? If so, what is the natural parameter?\n\nPoisson PDF: \\(f(y; \\theta) = \\frac{\\theta^y e^{-\\theta}}{y!}, \\quad y = 0, 1, 2, ...\\)\n\n\\(f(y; \\theta) = exp[y \\log (\\theta) - \\theta - log(y!)]\\)\n\\(a(y) = y\\)\n\\(b(\\theta) = \\log(\\theta)\\)\n\\(c(\\theta) = -\\theta\\)\n\\(d(y) = -\\log(y!)\\)\n\nYes, it’s in canonical form, and the natural parameter is \\(\\log(\\theta)\\). Easy peasy.\n\n\n\n\nWhat is the nuisance parameter? Is it in canonical form? What (if yes) is the natural parameter?\n\n\\[\\begin{align*}\nf(y; \\theta) &= \\frac{1}{\\sqrt{2\\pi \\sigma^2}} exp\\left[-\\frac{1}{2\\sigma^2}(y - \\mu)^2\\right]\\\\\n&= \\frac{1}{\\sqrt{2\\pi \\sigma^2}} exp\\left[\\frac{y\\mu}{\\sigma^2} - \\frac{\\mu^2}{2\\sigma^2}-\\frac{y^2}{2\\sigma^2}\\right]\\\\\n&= exp\\left[\\frac{y\\mu}{\\sigma^2} - \\frac{\\mu^2}{2\\sigma^2}-\\frac{y^2}{2\\sigma^2} -\\frac{1}{2}log(2\\pi\\sigma^2)  \\right]\\\\\n\\end{align*}\\]\n\n\\(a(y) = y\\)\n\\(b(\\mu) = \\frac{\\mu}{\\sigma^2}\\)\n\\(c(\\mu) = \\frac{\\mu^2}{2\\sigma^2}\\)\n\\(d(y) = - \\frac{y^2}{2\\sigma^2} - \\frac{log(2\\pi\\sigma^2)}{2}\\)\n\nThe nuisance parameter is \\(\\sigma^2\\). It is in canonical form, and the natural parameter is \\(\\mu/\\sigma^2\\).\n\n\n\n\nWhy do we care about the exponential family? Because it has some really useful properties. Specifically, we’re going to learn about calculating the mean and variance.\n\nProperty 1: \\(E[a(y)] = -c'(\\theta)/b'(\\theta)\\)\nProperty 2: \\(Var[a(y)] = \\frac{b''(\\theta) c'(\\theta) - c''(\\theta)b'(\\theta)}{[b'(\\theta)]^3}\\)\n\n\n\n\nRecall that the score function (or score statistic) is the first derivative of the log-likelihood function. Note that because it is a function of Y, it is considered a random variable. There are two extremely interesting properties of the score function.\nLet the random variable U represent the score function.\n\nProperty 1: \\(E[U] = 0\\)\nProperty 2: \\(Var[U] = \\frac{b''(\\theta)c'(\\theta)}{b'(\\theta)} - c''(\\theta) = I(\\theta)\\), where \\(I(\\theta)\\) is the Fisher’s information of \\(\\theta\\). Isn’t that crazy? The variance of the first derivative of the log-likelihood is the Fisher’s information.\n\n\n\n\n\nSuppose f(y; ) is a PDF. How must f(y; ) be written to conclude that it belongs to the exponential family?\nProperty 1 of the exponential family has to do with E[a(y)]. What is the property?\nProperty 2 of the exponential family has to do with V(a(y)). What is the property?\n\nBack"
  },
  {
    "objectID": "fall_24/b719/notes/september/sep_3.html#exponential-family",
    "href": "fall_24/b719/notes/september/sep_3.html#exponential-family",
    "title": "September 3, 2024 - September 5, 2024",
    "section": "",
    "text": "When an outcome is continuous, we consider a LR model like to be: \\(E(Y_i) = \\mu_i = X_i^T \\beta\\), where \\(T_i \\sim N(\\mu_i, \\sigma^2)\\)\nFor models with non-continuous outcomes, the distribution of \\(Y_i\\) is not normal. However, they may be in the exponential family and can share some of the nice properties of normality\nExponential family definition:\n\nDistribution of Y belongs to the exponential family if it can be written in the form \\(f(y; \\theta) = exp[a(y)b(\\theta) + c(\\theta) + d(y)]\\)\nCanonical form: if \\(a(y) = y\\), the distribution is in canonical form and \\(b(\\theta)\\) is said to be the natural parameter\nIf there are other parameters other than the parameter of interest (say \\(\\sigma^2\\) when we’re interested in \\(\\mu\\)), these are said to be nuisance parameters"
  },
  {
    "objectID": "fall_24/b719/notes/september/sep_3.html#examples",
    "href": "fall_24/b719/notes/september/sep_3.html#examples",
    "title": "September 3, 2024 - September 5, 2024",
    "section": "",
    "text": "Is the Poisson PDF in canonical form? If so, what is the natural parameter?\n\nPoisson PDF: \\(f(y; \\theta) = \\frac{\\theta^y e^{-\\theta}}{y!}, \\quad y = 0, 1, 2, ...\\)\n\n\\(f(y; \\theta) = exp[y \\log (\\theta) - \\theta - log(y!)]\\)\n\\(a(y) = y\\)\n\\(b(\\theta) = \\log(\\theta)\\)\n\\(c(\\theta) = -\\theta\\)\n\\(d(y) = -\\log(y!)\\)\n\nYes, it’s in canonical form, and the natural parameter is \\(\\log(\\theta)\\). Easy peasy.\n\n\n\n\nWhat is the nuisance parameter? Is it in canonical form? What (if yes) is the natural parameter?\n\n\\[\\begin{align*}\nf(y; \\theta) &= \\frac{1}{\\sqrt{2\\pi \\sigma^2}} exp\\left[-\\frac{1}{2\\sigma^2}(y - \\mu)^2\\right]\\\\\n&= \\frac{1}{\\sqrt{2\\pi \\sigma^2}} exp\\left[\\frac{y\\mu}{\\sigma^2} - \\frac{\\mu^2}{2\\sigma^2}-\\frac{y^2}{2\\sigma^2}\\right]\\\\\n&= exp\\left[\\frac{y\\mu}{\\sigma^2} - \\frac{\\mu^2}{2\\sigma^2}-\\frac{y^2}{2\\sigma^2} -\\frac{1}{2}log(2\\pi\\sigma^2)  \\right]\\\\\n\\end{align*}\\]\n\n\\(a(y) = y\\)\n\\(b(\\mu) = \\frac{\\mu}{\\sigma^2}\\)\n\\(c(\\mu) = \\frac{\\mu^2}{2\\sigma^2}\\)\n\\(d(y) = - \\frac{y^2}{2\\sigma^2} - \\frac{log(2\\pi\\sigma^2)}{2}\\)\n\nThe nuisance parameter is \\(\\sigma^2\\). It is in canonical form, and the natural parameter is \\(\\mu/\\sigma^2\\)."
  },
  {
    "objectID": "fall_24/b719/notes/september/sep_3.html#properties-of-the-exponential-family",
    "href": "fall_24/b719/notes/september/sep_3.html#properties-of-the-exponential-family",
    "title": "September 3, 2024 - September 5, 2024",
    "section": "",
    "text": "Why do we care about the exponential family? Because it has some really useful properties. Specifically, we’re going to learn about calculating the mean and variance.\n\nProperty 1: \\(E[a(y)] = -c'(\\theta)/b'(\\theta)\\)\nProperty 2: \\(Var[a(y)] = \\frac{b''(\\theta) c'(\\theta) - c''(\\theta)b'(\\theta)}{[b'(\\theta)]^3}\\)"
  },
  {
    "objectID": "fall_24/b719/notes/september/sep_3.html#the-score-function",
    "href": "fall_24/b719/notes/september/sep_3.html#the-score-function",
    "title": "September 3, 2024 - September 5, 2024",
    "section": "",
    "text": "Recall that the score function (or score statistic) is the first derivative of the log-likelihood function. Note that because it is a function of Y, it is considered a random variable. There are two extremely interesting properties of the score function.\nLet the random variable U represent the score function.\n\nProperty 1: \\(E[U] = 0\\)\nProperty 2: \\(Var[U] = \\frac{b''(\\theta)c'(\\theta)}{b'(\\theta)} - c''(\\theta) = I(\\theta)\\), where \\(I(\\theta)\\) is the Fisher’s information of \\(\\theta\\). Isn’t that crazy? The variance of the first derivative of the log-likelihood is the Fisher’s information."
  },
  {
    "objectID": "fall_24/b719/notes/september/sep_3.html#three-take-aways",
    "href": "fall_24/b719/notes/september/sep_3.html#three-take-aways",
    "title": "September 3, 2024 - September 5, 2024",
    "section": "",
    "text": "Suppose f(y; ) is a PDF. How must f(y; ) be written to conclude that it belongs to the exponential family?\nProperty 1 of the exponential family has to do with E[a(y)]. What is the property?\nProperty 2 of the exponential family has to do with V(a(y)). What is the property?\n\nBack"
  },
  {
    "objectID": "fall_24/b823/index.html",
    "href": "fall_24/b823/index.html",
    "title": "Statistical Programming for Big Data",
    "section": "",
    "text": "September\n\n\nOctober\n\n\nNovember\nTo review notes taken during class, follow this link."
  },
  {
    "objectID": "fall_24/b823/notes/september/sep_3.html",
    "href": "fall_24/b823/notes/september/sep_3.html",
    "title": "September 3, 2024 - September 5, 2024",
    "section": "",
    "text": "Relational models are built on first-order predicate logic. What does that mean? Let’s ask ChatGPT.\n\nAI Summary of first-order predicate logic from ChatGPT: First-order predicate logic (FOPL), also known as first-order logic (FOL), is a formal system used in mathematics, philosophy, and computer science to express statements about objects and their relationships using quantifiers (like “for all” and “there exists”) and predicates that denote properties or relations between objects. In relational data modeling, FOPL is applied to define the structure and constraints of data by expressing rules and conditions that must hold true for data entries in a database. For instance, it can be used to specify relationships between entities (like “every employee works for a department”) and enforce constraints such as uniqueness, referential integrity, or conditional dependencies, ensuring that the data adheres to the logical rules of the modeled domain.\n\nRelations are tables; tuples are rows\n\n\n\n\n\nAn entity is an identifiable “thing” of interest in the domain of interest. For example, an entity in a retail buisiness domain is a “customer.” A “Customer” is an identifiable “thing” of interest, represented by attributes like CustomerID (a unique identifier), Name, Email, and Address, which uniquely identify and describe each customer and relate to other entities, such as “Orders” or “Products.” The set of attributes that uniquely identify the entity is the natural key.\nThe E-R model focuses on the relationships betwen entities\nIn relational data modeling, there are two main stages of database design: the logical model and the physical model\n\nLogical Model: This defines the structure of the data independent of how it will be physically stored. It focuses on what data needs to be stored, the relationships between different entities (like “Customer” and “Order”), and the rules or constraints (like uniqueness or referential integrity). The logical model is typically represented using entity-relationship diagrams (ERDs) or similar notations that show entities, attributes, and relationships without concern for specific technical details.\nPhysical Model: This represents how the data will be stored on the database system. It translates the logical model into tables, columns, indexes, and keys, and considers performance, storage optimization, and access methods. The physical model depends on the specific database management system (DBMS) used (like MySQL, PostgreSQL, or Oracle) and addresses how data is actually stored on disk, how it will be indexed, and how queries will be optimized.\n\n\n\n\n\n\nHere are the three main relationship cardinalities:\n\n\\(\\{0, 1\\}:1\\) (0 or 1 to 1)\n\\(\\{0, 1\\}:n\\) (0 or 1 to many)\n\\(n:n\\) (many to many)\n\nCrow’s Feet: I’m not going to try to draw the crow’s feet, but they’re essentially a notation to write the relationship cardinalities\nResolving \\(n:n\\) relationships:\n\nSuppose we have a table of instructors that reference a table of courses (assume each course can have multiple instructors, like Gennevieve and Zeck). This is a many-to-many relationship problem. This is a problem (I believe) because the many-to-many relationships can’t be represented directly using just foreign keys in a relational database.\nTo solve this problem, you have a middle-man table. In this “junction” table (or whatever you call it), you have one-to-many relationship pointing at both the course table and the instructor table. If you know that only one professor will teach certain lessons of the course, you can have the middle-man table be a “lessons” table. Just know that “instructor” and “course” are considered strong entities, but “lessons” are considered weak because they only exist in the context of a course and an instructor.\n\n\n\n\n\n\nForeign keys\n\nThere are implicit foreign keys and explicit foreign keys. I don’t totally understand how implicit keys work, but essentially if the instructor teaches certain lessons and those lessons are part of a specific course, then the foreign key is explicit if the lesson doesn’t have any information about the instructor or the course. That’s why I don’t understand how they work. Regardless, if the lesson does have the instructor’s ID and the course ID, then the foreign key is explicit\n\nPrimary keys\n\nA surrogate primary key is a kind of like a local variable. It would the the “ID” in the table that’s generated by the system (e.g. autoincrement).\nA natural key is a unique identifier that’s more like a global variable (i.e. isn’t only contained in the database). An email address is a good example of a natural key.\n\nNote that a composite key is two or more attributes that uniquely identify an entity\n\n\n\n\n\nNormalization is used to minimize redundancy and improve data integrity (good things)\nFirst normal form\n\nDefinition: A relation is in first normal form iff no attribute domain has relations as elements.\nWhat the heck does that mean? Basically, all attributes have to be “atomic,” i.e. must not be tables, lists, arrays, etc.\n\nSecond normal form\n\nDefinition: A relation is in 2NF iff it is in 1NF and it does not have any non-prime attribute functionally dependent on any proper subset of any candidate key of the relation.\nCome again? Apart from being first normal, if any table has a composite natural key (more than one element), no column in that table depends on only a part of the composite key.\n\nThird normal form\n\nDefinition: A relation R is in 3NF iff it is in 2NF and every non-prime attribute of R is non-transitively dependent on every key of R.\nOne more time: I don’t know what this means. But here’s what Hilmar said: For every table, any attribute that is not part of a natural key depends directly on every key for the table.\n\nThe last thing I’ll mention is that Hilmar said that you definitely want your database in first normal form, preferably second, but you can sometimes get away with not having it in third\n\n\n\n\n\n\nAn entity is a thing of interest in a domain of interest that has attributes. The set of attributes that uniquely identify the entity is the natural key.\nIn the example of the instructors and courses, the lessons table acted as a middle-man or reference table that changed the many-to-many relationship problem into two one-to-many relationships.\nA primary key identifies an entity in the table; a foreign key identifies an entity in another table; a composite natural key is a set of two or more attributes that uniquely identify an entity; a surrogate key is like a local variable that is only understood by the database and doesn’t exist in the real world (like using “autoincrement”)"
  },
  {
    "objectID": "fall_24/b823/notes/september/sep_3.html#relational-data-modeling",
    "href": "fall_24/b823/notes/september/sep_3.html#relational-data-modeling",
    "title": "September 3, 2024 - September 5, 2024",
    "section": "",
    "text": "Relational models are built on first-order predicate logic. What does that mean? Let’s ask ChatGPT.\n\nAI Summary of first-order predicate logic from ChatGPT: First-order predicate logic (FOPL), also known as first-order logic (FOL), is a formal system used in mathematics, philosophy, and computer science to express statements about objects and their relationships using quantifiers (like “for all” and “there exists”) and predicates that denote properties or relations between objects. In relational data modeling, FOPL is applied to define the structure and constraints of data by expressing rules and conditions that must hold true for data entries in a database. For instance, it can be used to specify relationships between entities (like “every employee works for a department”) and enforce constraints such as uniqueness, referential integrity, or conditional dependencies, ensuring that the data adheres to the logical rules of the modeled domain.\n\nRelations are tables; tuples are rows\n\n\n\n\n\nAn entity is an identifiable “thing” of interest in the domain of interest. For example, an entity in a retail buisiness domain is a “customer.” A “Customer” is an identifiable “thing” of interest, represented by attributes like CustomerID (a unique identifier), Name, Email, and Address, which uniquely identify and describe each customer and relate to other entities, such as “Orders” or “Products.” The set of attributes that uniquely identify the entity is the natural key.\nThe E-R model focuses on the relationships betwen entities\nIn relational data modeling, there are two main stages of database design: the logical model and the physical model\n\nLogical Model: This defines the structure of the data independent of how it will be physically stored. It focuses on what data needs to be stored, the relationships between different entities (like “Customer” and “Order”), and the rules or constraints (like uniqueness or referential integrity). The logical model is typically represented using entity-relationship diagrams (ERDs) or similar notations that show entities, attributes, and relationships without concern for specific technical details.\nPhysical Model: This represents how the data will be stored on the database system. It translates the logical model into tables, columns, indexes, and keys, and considers performance, storage optimization, and access methods. The physical model depends on the specific database management system (DBMS) used (like MySQL, PostgreSQL, or Oracle) and addresses how data is actually stored on disk, how it will be indexed, and how queries will be optimized.\n\n\n\n\n\n\nHere are the three main relationship cardinalities:\n\n\\(\\{0, 1\\}:1\\) (0 or 1 to 1)\n\\(\\{0, 1\\}:n\\) (0 or 1 to many)\n\\(n:n\\) (many to many)\n\nCrow’s Feet: I’m not going to try to draw the crow’s feet, but they’re essentially a notation to write the relationship cardinalities\nResolving \\(n:n\\) relationships:\n\nSuppose we have a table of instructors that reference a table of courses (assume each course can have multiple instructors, like Gennevieve and Zeck). This is a many-to-many relationship problem. This is a problem (I believe) because the many-to-many relationships can’t be represented directly using just foreign keys in a relational database.\nTo solve this problem, you have a middle-man table. In this “junction” table (or whatever you call it), you have one-to-many relationship pointing at both the course table and the instructor table. If you know that only one professor will teach certain lessons of the course, you can have the middle-man table be a “lessons” table. Just know that “instructor” and “course” are considered strong entities, but “lessons” are considered weak because they only exist in the context of a course and an instructor.\n\n\n\n\n\n\nForeign keys\n\nThere are implicit foreign keys and explicit foreign keys. I don’t totally understand how implicit keys work, but essentially if the instructor teaches certain lessons and those lessons are part of a specific course, then the foreign key is explicit if the lesson doesn’t have any information about the instructor or the course. That’s why I don’t understand how they work. Regardless, if the lesson does have the instructor’s ID and the course ID, then the foreign key is explicit\n\nPrimary keys\n\nA surrogate primary key is a kind of like a local variable. It would the the “ID” in the table that’s generated by the system (e.g. autoincrement).\nA natural key is a unique identifier that’s more like a global variable (i.e. isn’t only contained in the database). An email address is a good example of a natural key.\n\nNote that a composite key is two or more attributes that uniquely identify an entity\n\n\n\n\n\nNormalization is used to minimize redundancy and improve data integrity (good things)\nFirst normal form\n\nDefinition: A relation is in first normal form iff no attribute domain has relations as elements.\nWhat the heck does that mean? Basically, all attributes have to be “atomic,” i.e. must not be tables, lists, arrays, etc.\n\nSecond normal form\n\nDefinition: A relation is in 2NF iff it is in 1NF and it does not have any non-prime attribute functionally dependent on any proper subset of any candidate key of the relation.\nCome again? Apart from being first normal, if any table has a composite natural key (more than one element), no column in that table depends on only a part of the composite key.\n\nThird normal form\n\nDefinition: A relation R is in 3NF iff it is in 2NF and every non-prime attribute of R is non-transitively dependent on every key of R.\nOne more time: I don’t know what this means. But here’s what Hilmar said: For every table, any attribute that is not part of a natural key depends directly on every key for the table.\n\nThe last thing I’ll mention is that Hilmar said that you definitely want your database in first normal form, preferably second, but you can sometimes get away with not having it in third"
  },
  {
    "objectID": "fall_24/b823/notes/september/sep_3.html#three-take-aways",
    "href": "fall_24/b823/notes/september/sep_3.html#three-take-aways",
    "title": "September 3, 2024 - September 5, 2024",
    "section": "",
    "text": "An entity is a thing of interest in a domain of interest that has attributes. The set of attributes that uniquely identify the entity is the natural key.\nIn the example of the instructors and courses, the lessons table acted as a middle-man or reference table that changed the many-to-many relationship problem into two one-to-many relationships.\nA primary key identifies an entity in the table; a foreign key identifies an entity in another table; a composite natural key is a set of two or more attributes that uniquely identify an entity; a surrogate key is like a local variable that is only understood by the database and doesn’t exist in the real world (like using “autoincrement”)"
  }
]